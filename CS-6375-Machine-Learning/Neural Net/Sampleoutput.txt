==================================================
Car Data
==========================================================================
Activation Layer: sigmoid
Layer1 weights:
-2.408691099903197
-7.453155791931439
-0.9498894934163047
-2.4232568539057375
-1.3297040966830334
-7.550181630741513
-0.270026825651017
-3.133307142703767
-0.368081504414193
0.5309180492125215
-0.12209812812789947
1.2890129288582803
1.3324131384528608
-3.119599005628631
-9.20227474959789
1.8513926193583146
1.3878538601523145
0.9082910141462819
0.1776600984258708
3.873433009277378
-0.17070307167488766
8.959710006445375
-9.059892547673156
-5.21625252886736
Layer2 weights:
-3.928272610033527
-1.1329912987038342
-6.956387751826737
-7.718029174576864
-1.3925043394436554
16.8139582436188
-5.21389033191002
-7.466376145161801
Layer3 weights:
-3.0042671302574755
-8.66283256192353
After 1000 iterations, the train error is 0.19494970190927835
Activation Layer: sigmoid
Test dataset error is 0.19510588598020098
======================================================================================================================================================================
Activation Layer: tanh
Layer1 weights:
484142.076621353
-1316399.7523020823
-268763.4428382861
281705.127365997
408941.729838627
-983064.6749308722
-106772.87006149866
221676.186127753
-64015.236928898754
478923.3044171081
97935.60760058738
82352.46731870317
-577500.4326145438
1253078.936977377
198366.2283756191
-543823.3688186263
-225851.9933086995
805770.9903772088
210064.88494638383
-179391.78533533428
-767931.5163998946
2398095.8460613834
476075.74840193207
-394014.150496532
Layer2 weights:
-1857.0749998985307
369.51876497560045
2367.3067016322943
303.56466449770073
2009.4807485894949
-446.6034047638035
-1633.7156075658984
-553.6369622930688
Layer3 weights:
-76.07528160386278
14.83980920093287
After 1000 iterations, the train error is 0.455466669848281
Activation Layer: tanh
Test dataset error is 1.2217391304347827
======================================================================================================================================================================
Activation Layer: relu
Layer1 weights:
-2.1072939409054454
2.251818668418548
-1.271172426512597
-0.3097357018452183
-1.1406340363661704
-0.9228988798191718
-1.0113303160994984
-0.26639974780897424
0.8260721192193266
-0.14583277841692066
-0.9178627024163573
0.4247246896664829
3.6100124626721932
-1.3155847102195874
-2.0257761439591606
0.14682911154915862
-1.6788061754692474
0.7614863475680191
-0.22351633035429563
-0.5786913498801209
-1.1487218132829125
1.636561907001484
0.8471464182337023
0.43539726356109265
Layer2 weights:
-3.072600604587118
0.8014920381581111
-1.4100651366398271
-0.43528162908403917
-1.8853890710137182
0.8024951121581647
-0.8233288345686445
0.5060974649406501
Layer3 weights:
-0.802051724251249
-7.60301343137885
After 1000 iterations, the train error is 0.36314265025343956
Activation Layer: relu
Test dataset error is 0.34492753623188405
==============================================================================================================================================
Adult Data
==========================================================================
Activation Layer: sigmoid
Layer1 weights:
-0.5932087206768409
0.11072381659847452
0.11438803904325878
-1.2797768382797112
-0.7518937184488582
-0.8552641928943412
-0.6799118255768243
-0.3278560105640756
-0.20526887464988064
0.08338813671665218
-0.2348071256151631
0.28008497468914556
-0.6298254447014128
0.6343538393165945
-1.3665257776854034
0.08904991602129625
-0.6302138564517974
-0.2978227023187179
0.47100714830293144
-1.6910910001267376
0.9794706220789923
1.1803725973503316
-1.3865460347512417
1.0953433194853348
0.6587763946392752
0.6897888013865665
-0.7831107149259704
-1.151124788116436
-0.28030455714643376
1.0615667433783722
-2.2290208064611265
0.778302766166636
0.8967883788176133
-0.023965423122330014
0.8839966394589567
-0.5643873190641395
0.016936547577168986
0.3713428163331551
0.0929067309016217
-0.322400183785465
0.7794394460232872
0.33245654481214126
0.19816581777218553
0.08611796341341156
-0.9253027918856277
-0.26017720360649543
1.6832513745768687
-0.7284604932850305
-0.8031918676212815
-1.0093512297907352
0.033603177259424126
-0.49879712179759284
-0.5383582289211879
-0.48407133336408376
-0.022627499979991136
-0.6487559311328647
Layer2 weights:
9.534222549301411
-1.4147986642027184
10.457770601843375
-0.40145870994218696
14.235307611820947
-1.3322306529202372
11.182580982425215
-1.001933306513817
Layer3 weights:
-39.25318486224512
-35.77147855303012
After 1000 iterations, the train error is 0.1246684350132626
Activation Layer: sigmoid
Test dataset error is 0.12359084880636605
======================================================================================================================================================================
Activation Layer: tanh
Layer1 weights:
44433371546.11774
32809206032.922382
10492915033.307487
-6456966348.99424
15156057563.467173
8414692493.4146185
-2449247116.2331333
-4642860865.19656
-4977012450.454724
-3225944147.487746
4450939109.82585
1833756449.4115496
6589434995.418563
4869856135.800528
-5095748933.1825485
-7565356921.775813
9711755023.193573
23919437415.29444
7372393881.891857
4078016099.908371
-55581871960.5403
-38236703082.15232
-14134022001.485588
12719601425.745037
9228942737.04729
6411324860.837789
-6861471634.980988
-790501500.9166946
-86609941521.47293
-56945889812.120316
-15991579549.139557
25156098443.750004
17275803901.052612
12873302490.583963
-1001957252.1495895
-3138132403.1671085
73013104077.16321
51421837940.20332
14305606151.455513
-17505481300.850708
4625545061.065437
-8474995967.929199
14411950503.209244
9395133114.953682
8452440368.316032
7705912503.748798
3848456056.8721905
2913545164.064295
41166978396.119
30930702336.968033
6466661216.97036
-4149002631.294544
3906968976.0666094
4351371792.707495
-5311065185.7197
-4596823277.065948
Layer2 weights:
-392008.1326529058
59635.70002149016
71855.18283693689
251304.83493720007
-348144.1196335708
-70450.56088186859
-213333.92157283623
86322.11366637162
Layer3 weights:
-1285.8463535170574
-216.8978617187122
After 1000 iterations, the train error is 0.8062831564986738
Activation Layer: tanh
Test dataset error is 0.44338527851458887
======================================================================================================================================================================
Activation Layer: relu
Layer1 weights:
-1804.9011453956584
1104.7870557012225
3752.765878955943
-641.3421615194165
-2810.5465436424115
8395.424928207898
3409.897604389052
-795.4712505856398
-275.03886901279276
561.5597184944917
610.7190467748663
410.38431923998047
-1046.6363060349602
-6188.565488675541
2043.9361538809303
368.30922565795544
-1970.4099337446528
-1192.5383050812213
3357.244513725214
-543.870061405857
5216.0309406426895
-10620.634830273382
-2139.515817325662
1176.4961935596314
2412.7204923296913
-5237.425585398336
2212.340649138116
-656.0953089812473
3269.693796513033
-14858.7045104529
-4557.330398762598
1114.198712314637
1683.4128063602345
1572.897802351355
-1087.341469958393
-729.5959032118486
-2318.8795988008037
9761.258141997681
6536.571698108157
-298.710674391356
-688.8500584515489
2070.5309293087003
1500.9601948747322
-172.07736047139576
-993.9113128122641
-16724.57925240246
-11589.192604335554
-24.36150909301503
-6670.160611992367
15079.95476604401
8613.302178500779
-862.8453518149856
-773.9468257258114
365.55519411656405
-465.9665139868909
-718.6399153766589
Layer2 weights:
2268.4661036900247
-13769.903941045284
10186.015456894023
-47162.78697270915
496.56359639222967
-40736.88403939824
1862.7358074269791
-10122.76772018911
Layer3 weights:
-2910.1348625664655
-29008.33365417703
After 1000 iterations, the train error is 0.1246684350132626
Activation Layer: relu
Test dataset error is 0.12359084880636605
==============================================================================================================================================
Iris Data
==========================================================================
Activation Layer: sigmoid
Layer1 weights:
-0.5211166116592761
0.8370880824763078
0.28649535894846817
0.35131220057176177
1.2871641922326633
-1.3150303020559988
-1.3823867904951366
-1.2282006712601
-1.5550392399690347
0.7387249705089945
1.4308490714134323
1.5494960804763107
-1.8735575322100015
1.4020817707567375
0.6451360818232892
1.4991745243041095
Layer2 weights:
-7.113277273422253
-7.912430263047278
1.2636074168832405
1.5381780125098816
0.7623516562911995
0.9876748042553807
1.6800738171687652
2.626748440205265
Layer3 weights:
2.6789069652065867
5.874245917611267
After 1000 iterations, the train error is 0.19880506095238812
Activation Layer: sigmoid
Test dataset error is 0.24601025840897273
======================================================================================================================================================================
Activation Layer: tanh
Layer1 weights:
501.6655487517873
1903.8505018558824
1537.5826297667327
1012.8337987006972
2808.929077402832
1923.974582311812
-1880.0384409893006
-17.452333096263725
-158.7359114023639
1428.7865075957768
2351.633758123947
1330.7862317253132
834.7180730788539
2458.4628054147074
1813.840076125241
1565.145027572135
Layer2 weights:
118.18960886524688
60.42536501262187
-29.352755496852755
22.46705897855498
80.81598103956783
17.540816240183734
143.86817475839953
19.66207238208244
Layer3 weights:
1.0878897868509307
0.15496119950785692
After 1000 iterations, the train error is 0.4485372714739673
Activation Layer: tanh
Test dataset error is 0.5777938902267861
============================================================================================